#For 10 coins, let pi.i denote the probability of a head for coin i. You flip each coin 5 times. The
sample numbers of heads are (2,4,1,3,3,5,4,2,3,1)

#making data frame
coin = c(1:10)
heads = c(2,4,1,3,3,5,4,2,3,1)
tails = 5-heads
q1 = as.data.frame(cbind(coin,heads,tails))
pi = q1$heads / 5
cbind(q1, pi)

q1$coin = factor(q1$coin)
q1$pi = q1$heads / 5

#fitting random effects model
library(lme4)
coins.model <- glmer(cbind(heads, 5-heads) ~ 1 + (1|coin),family=binomial, data=q1)
summary(coins.model)

#obtain fitted values
coins.fitted <- fitted(coins.model)
coins.fitted

q1$predicted = coins.fitted
q1

#comparing predicted and sample probabilities
library(ggplot2)

ggplot(q1, aes(x=predicted, y=pi))+
geom_point(color="mediumslateblue")+
ggtitle("Observed vs Predicted Probabilities")+
theme(plot.title = element_text(hjust = 0.5))+
xlab("Predicted")+
ylab("Observed")

#calculating mean square errors
mse.predicted = mean((q1$predicted - 0.5)**2)
mse.predicted

mse.observed = mean((q1$pi - 0.5)**2)
mse.observed


#set up data
id <- rep(1:2276, each=3)
yes <- c(rep(c(1,1,1),911),
rep(c(1,1,0),538),
rep(c(0,1,1),44),
rep(c(0,1,0),456),
rep(c(1,0,1),3),
rep(c(1,0,0),43),
rep(c(0,0,1),2),
rep(c(0,0,0),279))
instance <- rep(c("cigs","alc","mj"), 2276)
teens.subject <- data.frame(id, yes, instance)
teens.subject$instance <- factor(teens.subject$instance,
levels=c("cigs","alc","mj"))

# part a - making gee model
library(gee)

gee.mod <- gee(yes == "1" ~ instance, id = id, data = teens.subject, family = binomial, corstr = "exchange")
summary(gee.mod)

##part a - making confidence intervals
summary(gee.mod)$coefficients

gee.b2 = summary(gee.mod)$coefficients[2,1]
gee.z2 = summary(gee.mod)$coefficients[2,5]
gee.se2 = summary(gee.mod)$coefficients[2,4]
l.2 = gee.b2 - (gee.z2*gee.se2)
u.2 = gee.b2 + (gee.z2*gee.se2)
ci.2 = cbind(l.2, u.2)
ci.2

gee.b3 = summary(gee.mod)$coefficients[3,1]
gee.z3 = summary(gee.mod)$coefficients[3,5]
gee.se3 = summary(gee.mod)$coefficients[3,4]
l.3 = gee.b3 - (gee.z3*gee.se3)
u.3 = gee.b3 + (gee.z3*gee.se3)
ci.3 = cbind(l.3, u.3)
ci.3

exp(1.136)

exp(-2.169)

#likelihood ratio test
model.3 <- glmer((yes=="1") ~ 1 + (1|id), data=teens.subject, family=binomial)
library(lmtest)
lrtest(model.2c, model.3)

#estimating random effects variance
hist(ranef(model.2c)$id[,1], xlab=expression(hat(U)[i]), main="Random Effects")


#the estimated odds of saying yes to using any substance if they also have responded yes to alcohol is exp(1.136) = 3.114 times the estimated odds of a student who said no to using
alcohol.
#for a student who said yes to using marijuana, the estimated odds of
saying yes to any substance is exp(-2.169) = 0.1142919 times the odds of those who just said yes to using
cigarettes.

#From the model, the variance of random effects is 9.141 . I think this is a pretty high value. This
means that there is a large amount of variability between individuals across all factors. Much of within
factor variance is due to individual differences.

#The GEE and GLMM give different estimates for these parameters. The GLMM model is subjectspecific and contains random and fixed effects; fundamentally it estimates parameters differently than
a GEE does. The GEE model is a marginal model and aims to predict the overall effect n a population.
It does not use likelihood based methods like the GLMM, it does not assume normal distribution of
data. Since there is some variability among subjects in the data, the GLMM and GEE models generate
different estimates for these parameters.


summary(model.2c)$coefficients
summary(gee.mod)$coefficients


